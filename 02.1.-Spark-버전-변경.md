# **개요**

- 설치된 Spark의 버전을 바꾸기 위한 문서입니다.

------

# **설치할 소프트웨어**

- Apache Spark(2.1.2)

------



## 1. Spark 버전 확인

```bash
# 현재 설치된 스파크 버전 확인
$ spark-submit --version
```

설치된 버전이 2.1.2가 아닌 경우 계속 진행합니다.



## 2. Spark 2.1.2 설치

```bash
# Download and install spark - ver. 2.1.2
$ cd $HOME
$ wget http://mirror.apache-kr.org/spark/spark-2.1.2/spark-2.1.2-bin-hadoop2.7.tgz
$ tar xvzf spark-2.1.2-bin-hadoop2.7.tgz

# 설치 파일을 다운로드 폴더로 이동합니다
$ mv spark-2.1.2-bin-hadoop2.7.tgz ./downloads/
```



## 3. Spark Symbolic link 수정

```bash
$ cd $HOME

# Remove old symbolic link
$ rm spark

# Make symbolic link for spark
$ ln -s spark-2.1.2-bin-hadoop2.7 spark
```



## 4. Spark 설정

```bash
$ cd $HOME/spark/conf

# spark-env.sh.template을 복사하여 spark-env.sh 생성
$ cp spark-env.sh.template spark-env.sh


# 수정 내용, 아래의 내용을 spark-env.sh 에 덧붙여 줍니다.
export SPARK_MASTER_WEBUI_PORT=9090
export SPARK_WORKER_WEBUI_PORT=9091
export HADOOP_CONF_DIR=/home/ubuntu/hadoop/etc/hadoop
```



## 5. Spark 버전 확인

```bash
# 새로운 스파크 버전 확인
$ spark-submit --version
```

설치된 버전이 2.1.2가 나와야 합니다.